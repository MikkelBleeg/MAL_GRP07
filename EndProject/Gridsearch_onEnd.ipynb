{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from time import time\n",
    "from sklearn import svm, preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import sys,os\n",
    "sys.path.append(os.path.expanduser('ProjectFunctions'))\n",
    "from ProjectFunctions import LoadShapes as LS\n",
    "from ProjectFunctions import GridReport as GR\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK, Load time=50.1\n"
     ]
    }
   ],
   "source": [
    "#TODO load the dataset:\n",
    "start = time()\n",
    "\n",
    "X, y = LS.getShapes()\n",
    "\n",
    "t = time()-start\n",
    "print(f\"OK, Load time={t:0.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X:  (14970, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "X_shape = X.shape\n",
    "print(\"The shape of X: \", X_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new shape of the reshaped X:  (14970, 40000)\n",
      "The shape of X ready to be inputed in the CNN:  (40000,)\n"
     ]
    }
   ],
   "source": [
    "#split\n",
    "X_r = X.reshape(14970, 200*200)\n",
    "\n",
    "X_rShape = X_r.shape\n",
    "print(\"The new shape of the reshaped X: \", X_rShape)\n",
    "\n",
    "input_X_rShape = X_rShape[1:]\n",
    "print(\"The shape of X ready to be inputed in the CNN: \", input_X_rShape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done preparing data for neural networks.\n"
     ]
    }
   ],
   "source": [
    "X_neuralReady=np.array(X_r)/255\n",
    "\n",
    "print(\"Done preparing data for neural networks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done splitting train and test data.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size=0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, shuffle=True)\n",
    "\n",
    "print(\"Done splitting train and test data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done splitting train and test data ready for neural networks.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Xnr_train, Xnr_test, ynr_train, ynr_test = train_test_split(X_neuralReady, y, test_size=test_size, random_state=42, shuffle=True)\n",
    "\n",
    "print(\"Done splitting train and test data ready for neural networks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnr_train, Xnr_test, ynr_train, ynr_test = Xnr_train[:1000], Xnr_test[:1000], ynr_train[:1000], ynr_test[:1000]\n",
    "print(\"Done splitting train into length of 1000.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup search parameters\n",
    "model = svm.SVC(gamma=0.001) # NOTE: gamma=\"scale\" does not work in older Scikit-learn frameworks, \n",
    "                             # FIX:  replace with model = svm.SVC(gamma=0.001)\n",
    "\n",
    "\n",
    "tuning_parameters = {\n",
    "    'kernel':('linear', 'rbf'), \n",
    "    'C':[0.1, 1, 10]\n",
    "}\n",
    "\n",
    "\n",
    "CV=5\n",
    "VERBOSE=0\n",
    "# Run GridSearchCV for the model\n",
    "start = time()\n",
    "grid_tuned = GridSearchCV(model, tuning_parameters, cv=CV, scoring='f1_micro', verbose=VERBOSE, n_jobs=-1, iid=True)\n",
    "grid_tuned.fit(Xnr_train, ynr_train)\n",
    "t = time()-start\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH TIME: 379.60 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'C': 1, 'kernel': 'rbf'}\n",
      "\tbest 'f1_micro' score=1.0\n",
      "\tbest index=3\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tSVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.998 (+/-0.005) for {'C': 0.1, 'kernel': 'linear'}\n",
      "\t[ 1]: 0.997 (+/-0.012) for {'C': 0.1, 'kernel': 'rbf'}\n",
      "\t[ 2]: 0.998 (+/-0.005) for {'C': 1, 'kernel': 'linear'}\n",
      "\t[ 3]: 1.000 (+/-0.000) for {'C': 1, 'kernel': 'rbf'}\n",
      "\t[ 4]: 0.998 (+/-0.005) for {'C': 10, 'kernel': 'linear'}\n",
      "\t[ 5]: 1.000 (+/-0.000) for {'C': 10, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Circle       1.00      1.00      1.00       218\n",
      "      Square       1.00      1.00      1.00       273\n",
      "        Star       1.00      1.00      1.00       269\n",
      "    Triangle       1.00      1.00      1.00       240\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "\n",
      "CTOR for best model: SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "\n",
      "best: dat=N/A, score=1.00000, model=SVC(C=1,kernel='rbf')\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Report result\n",
    "b0, m0= GR.FullReport(grid_tuned , Xnr_test, ynr_test, t)\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup search parameters\n",
    "model = svm.SVC(gamma=0.001) # NOTE: gamma=\"scale\" does not work in older Scikit-learn frameworks, \n",
    "                             # FIX:  replace with model = svm.SVC(gamma=0.001)\n",
    "\n",
    "tuning_parameters = {\n",
    "    'kernel':('linear', 'rbf'), \n",
    "    'C':[0.1, 1, 10]\n",
    "}\n",
    "\n",
    "CV=5\n",
    "VERBOSE=0\n",
    "# Run RandomizedSearchCV for the model\n",
    "start = time()\n",
    "random_tuned = RandomizedSearchCV(model, tuning_parameters, random_state=42, n_iter=4, cv=CV, scoring='f1_micro', verbose=VERBOSE, n_jobs=-1, iid=True)\n",
    "random_tuned.fit(Xnr_train, ynr_train)\n",
    "t = time()-start\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH TIME: 275.86 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'kernel': 'rbf', 'C': 10}\n",
      "\tbest 'f1_micro' score=1.0\n",
      "\tbest index=2\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tSVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.998 (+/-0.005) for {'kernel': 'linear', 'C': 0.1}\n",
      "\t[ 1]: 0.997 (+/-0.012) for {'kernel': 'rbf', 'C': 0.1}\n",
      "\t[ 2]: 1.000 (+/-0.000) for {'kernel': 'rbf', 'C': 10}\n",
      "\t[ 3]: 0.998 (+/-0.005) for {'kernel': 'linear', 'C': 1}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Circle       1.00      1.00      1.00       218\n",
      "      Square       1.00      1.00      1.00       273\n",
      "        Star       1.00      1.00      1.00       269\n",
      "    Triangle       1.00      1.00      1.00       240\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "\n",
      "CTOR for best model: SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "\n",
      "best: dat=N/A, score=1.00000, model=SVC(C=10,kernel='rbf')\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Report result\n",
    "b0, m0= GR.FullReport(random_tuned , Xnr_test, ynr_test, t)\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDClassifier(eta0=0.1) \n",
    "tuning_parameters = {\n",
    "    'alpha' : [0.001, 0.01, 0.1, 1],\n",
    "    'max_iter': [1, 10, 100, 1000],\n",
    "    'learning_rate': ('constant','optimal','invscaling','adaptive'),\n",
    "    'n_iter_no_change': [5, 10, 15],\n",
    "    'loss': ('hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_loss', 'epsilon_insensitive'),\n",
    "    \n",
    "}\n",
    "\n",
    "CV=5\n",
    "VERBOSE=0\n",
    "# Run RandomizedSearchCV for the model\n",
    "start = time()\n",
    "SGDRandom_tuned = RandomizedSearchCV(model, tuning_parameters, random_state=42, n_iter=8, cv=CV, scoring='f1_micro', verbose=VERBOSE, n_jobs=-1, iid=True)\n",
    "SGDRandom_tuned.fit(Xnr_train, ynr_train)\n",
    "t = time()-start\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH TIME: 1184.06 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'n_iter_no_change': 15, 'max_iter': 500, 'loss': 'huber', 'learning_rate': 'adaptive', 'alpha': 0.01}\n",
      "\tbest 'f1_micro' score=0.999\n",
      "\tbest index=4\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tSGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.1, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='adaptive', loss='huber',\n",
      "              max_iter=500, n_iter_no_change=15, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.732 (+/-0.425) for {'n_iter_no_change': 10, 'max_iter': 100, 'loss': 'huber', 'learning_rate': 'adaptive', 'alpha': 0.01}\n",
      "\t[ 1]: 0.874 (+/-0.058) for {'n_iter_no_change': 10, 'max_iter': 1, 'loss': 'log', 'learning_rate': 'invscaling', 'alpha': 0.1}\n",
      "\t[ 2]: 0.294 (+/-0.100) for {'n_iter_no_change': 15, 'max_iter': 500, 'loss': 'epsilon_insensitive', 'learning_rate': 'optimal', 'alpha': 0.01}\n",
      "\t[ 3]: 0.321 (+/-0.183) for {'n_iter_no_change': 10, 'max_iter': 1000, 'loss': 'epsilon_insensitive', 'learning_rate': 'constant', 'alpha': 0.1}\n",
      "\t[ 4]: 0.999 (+/-0.004) for {'n_iter_no_change': 15, 'max_iter': 500, 'loss': 'huber', 'learning_rate': 'adaptive', 'alpha': 0.01}\n",
      "\t[ 5]: 0.997 (+/-0.005) for {'n_iter_no_change': 5, 'max_iter': 1000, 'loss': 'perceptron', 'learning_rate': 'adaptive', 'alpha': 0.01}\n",
      "\t[ 6]: 0.998 (+/-0.005) for {'n_iter_no_change': 15, 'max_iter': 500, 'loss': 'epsilon_insensitive', 'learning_rate': 'adaptive', 'alpha': 0.1}\n",
      "\t[ 7]: 0.701 (+/-0.304) for {'n_iter_no_change': 5, 'max_iter': 1, 'loss': 'modified_huber', 'learning_rate': 'adaptive', 'alpha': 0.01}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Circle       1.00      0.99      0.99       218\n",
      "      Square       0.99      1.00      0.99       273\n",
      "        Star       1.00      1.00      1.00       269\n",
      "    Triangle       1.00      1.00      1.00       240\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "\n",
      "CTOR for best model: SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.1, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='adaptive', loss='huber',\n",
      "              max_iter=500, n_iter_no_change=15, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "\n",
      "best: dat=N/A, score=0.99900, model=SGDClassifier(alpha=0.01,learning_rate='adaptive',loss='huber',max_iter=500,n_iter_no_change=15)\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Report result\n",
    "b0, m0= GR.FullReport(SGDRandom_tuned , Xnr_test, ynr_test, t)\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup search parameters\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "tuning_parameters = {\n",
    "    'n_neighbors' : [3, 5, 8],\n",
    "    'weights' : ['uniform', 'distance'],\n",
    "    'metric' : ['minkowski', 'euclidean', 'manhattan'],\n",
    "    'leaf_size' : [10, 30, 50]\n",
    "}\n",
    "    \n",
    "CV=5\n",
    "VERBOSE=0\n",
    "# Run RandomizedSearchCV for the model\n",
    "start = time()\n",
    "KNRandom_tuned = RandomizedSearchCV(model, tuning_parameters, random_state=42, n_iter=6, cv=CV, scoring='f1_micro', verbose=VERBOSE, n_jobs=-1, iid=True)\n",
    "KNRandom_tuned.fit(Xnr_train, ynr_train)\n",
    "t = time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH TIME: 169.08 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'weights': 'distance', 'n_neighbors': 3, 'metric': 'minkowski', 'leaf_size': 30}\n",
      "\tbest 'f1_micro' score=1.0\n",
      "\tbest index=0\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tKNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
      "                     weights='distance')\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 1.000 (+/-0.000) for {'weights': 'distance', 'n_neighbors': 3, 'metric': 'minkowski', 'leaf_size': 30}\n",
      "\t[ 1]: 1.000 (+/-0.000) for {'weights': 'distance', 'n_neighbors': 3, 'metric': 'manhattan', 'leaf_size': 50}\n",
      "\t[ 2]: 1.000 (+/-0.000) for {'weights': 'uniform', 'n_neighbors': 3, 'metric': 'manhattan', 'leaf_size': 50}\n",
      "\t[ 3]: 1.000 (+/-0.000) for {'weights': 'uniform', 'n_neighbors': 3, 'metric': 'manhattan', 'leaf_size': 10}\n",
      "\t[ 4]: 1.000 (+/-0.000) for {'weights': 'uniform', 'n_neighbors': 5, 'metric': 'euclidean', 'leaf_size': 50}\n",
      "\t[ 5]: 1.000 (+/-0.000) for {'weights': 'distance', 'n_neighbors': 8, 'metric': 'minkowski', 'leaf_size': 10}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Circle       1.00      1.00      1.00       218\n",
      "      Square       1.00      1.00      1.00       273\n",
      "        Star       1.00      1.00      1.00       269\n",
      "    Triangle       1.00      1.00      1.00       240\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "\n",
      "CTOR for best model: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
      "                     weights='distance')\n",
      "\n",
      "best: dat=N/A, score=1.00000, model=KNeighborsClassifier(leaf_size=30,metric='minkowski',n_neighbors=3,weights='distance')\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Report result\n",
    "b0, m0= GR.FullReport(random_tuned , Xnr_test, ynr_test, t)\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion on optimization\n",
    "\n",
    "For optimizing of chosen dataset, GridSearchCV and RandomSearchCV was used, in search of hyperparameters. Both optimization method originates from scikit-learn. To find the best optimization, the search methods was used with different combinations of tuning parameters, implemented in a parameter_grid. the search methods will try to optimize the models using the parameters given, which then results in scores to given parameters. The scores indicates which tuning parameters are best for optimizing. The best scoring parameters is known as the best parameters for the given dataset.\n",
    "\n",
    "When comparing the GridSearch and RandomSearch, the RandomSearch is slightly faster, which is expected as it doesn't try with all combinations. As seen in the results above, the search found the best estimator for optimizing by trying combinations with the given tuning parameters. The various combinations saw scores of 0.997 and 0.998 for SVM model.\n",
    "With the best estimator for optimization a score of 1, which is a perfect score,was achieved. The tuning parameter for the best estimator is found to be: Kernel=rbf and C-gamma=1.\n",
    "The SGDClassifier gave various results with for optimization. As seen in the results, the score could swing 0.294 up to 0.999. If given more iterations, it could be assumed the hyperparameter tuning would find the best estimator for given dataset. \n",
    "As for KNeighbor model, each parameter gave a score of 1, which can be very questionable, whether it is a valid tuning model for these types of data.\n",
    "\n",
    "No further optimization method was used as the grid and random search achieved a perfect score. Other methods could used to speed up the optimization, such as different types of regression, but may cost effectiveness on the score.\n",
    "Regression may not be very suitable for this type of data, as it consists of images. Regression is typically used for data consisting of values, used to predict for example house value. \n",
    "\n",
    "But with a score of 1, it could be questionable whether the system is overfitted.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
